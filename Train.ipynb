{
 "metadata": {
  "name": "",
  "signature": "sha256:d69ae41020a557ecf3f82e2bdd8cc8f01a098b3a7b3bdcea292cdacdc2504889"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# coding: utf-8\n",
      "\n",
      "# In[10]:\n",
      "\n",
      "import numpy as np\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import lasagne\n",
      "import librosa as lb\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "get_ipython().magic(u'matplotlib inline')\n",
      "\n",
      "import gzip\n",
      "import pickle\n",
      "import os\n",
      "import os.path\n",
      "\n",
      "\n",
      "# In[11]:\n",
      "\n",
      "# Seed for reproduciblity\n",
      "np.random.seed(42)\n",
      "\n",
      "\n",
      "# In[12]:\n",
      "\n",
      "# get_ipython().system(u'wget -N http://deeplearning.net/data/mnist/mnist.pkl.gz')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wav_dir = 'converted_music/miniMusic/'\n",
      "X = []\n",
      "Y = []\n",
      "clazzes = {}\n",
      "for root, dirs, files in os.walk(wav_dir):\n",
      "    X += list(map(lambda x: os.path.join(root, x), files))\n",
      "    clazz = clazzes[root] if (root in dirs) else len(clazzes)\n",
      "    clazzes[root] = clazz\n",
      "    for _ in files:\n",
      "        Y.append(clazz-1)\n",
      "    \n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
      "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.11)\n",
      "print(set(y_train))\n",
      "\n",
      "print(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python3.4/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
        "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
        "/usr/local/lib/python3.4/dist-packages/matplotlib/backends/backend_gtk3agg.py:18: UserWarning: The Gtk3Agg backend is known to not work on Python 3.x with pycairo. Try installing cairocffi.\n",
        "  \"The Gtk3Agg backend is known to not work on Python 3.x with pycairo. \"\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{0, 1}\n",
        "['converted_music/miniMusic/rock/alligot.mid', 'converted_music/miniMusic/rock/bluecollarman.mid', 'converted_music/miniMusic/rock/dream_world.mid', 'converted_music/miniMusic/rock/douwant.mid', 'converted_music/miniMusic/classical/018506b_.mid', 'converted_music/miniMusic/classical/018806b_.mid', 'converted_music/miniMusic/rock/babyinbk.mid', 'converted_music/miniMusic/rock/bless_the_beasts_and_the_children.mid', 'converted_music/miniMusic/rock/day_we_fall_in_love.mid', 'converted_music/miniMusic/rock/babe.mid', 'converted_music/miniMusic/rock/bungbill.mid', 'converted_music/miniMusic/classical/015804b_.mid', 'converted_music/miniMusic/classical/015309b_.mid', 'converted_music/miniMusic/rock/dontpass.mid', 'converted_music/miniMusic/rock/dizzlizz.mid', 'converted_music/miniMusic/classical/016106b_.mid', 'converted_music/miniMusic/classical/016506b_.mid', 'converted_music/miniMusic/rock/actnatur.mid', 'converted_music/miniMusic/classical/018707b_.mid', 'converted_music/miniMusic/rock/close_to_you.mid', 'converted_music/miniMusic/rock/comesail.mid', 'converted_music/miniMusic/rock/digit.mid', 'converted_music/miniMusic/rock/anna.mid', 'converted_music/miniMusic/classical/013906b_.mid', 'converted_music/miniMusic/classical/015505b_.mid', 'converted_music/miniMusic/classical/015705b_.mid', 'converted_music/miniMusic/rock/allmylove.mid', 'converted_music/miniMusic/rock/acrossu.mid', 'converted_music/miniMusic/classical/017507b_.mid', 'converted_music/miniMusic/rock/dearprud.mid', 'converted_music/miniMusic/classical/017405b_.mid', 'converted_music/miniMusic/classical/015905b_.mid', 'converted_music/miniMusic/classical/019007b_.mid', 'converted_music/miniMusic/rock/africa.mid', 'converted_music/miniMusic/classical/015305b_.mid', 'converted_music/miniMusic/rock/a_song_for_you.mid', 'converted_music/miniMusic/rock/door_into_summer.mid', 'converted_music/miniMusic/classical/016206blpz.mid', 'converted_music/miniMusic/classical/017206vn.mid', 'converted_music/miniMusic/classical/018405b_.mid', 'converted_music/miniMusic/rock/dontboth.mid', 'converted_music/miniMusic/rock/atasteof.mid', 'converted_music/miniMusic/classical/019007binst.mid', 'converted_music/miniMusic/classical/015606b_.mid', 'converted_music/miniMusic/classical/019406b_.mid', 'converted_music/miniMusic/rock/desperado.mid', 'converted_music/miniMusic/classical/018405unk.mid', 'converted_music/miniMusic/classical/017807b_.mid', 'converted_music/miniMusic/classical/016406b_.mid', 'converted_music/miniMusic/rock/devilin.mid', 'converted_music/miniMusic/classical/018305b_.mid', 'converted_music/miniMusic/rock/babyitsu.mid', 'converted_music/miniMusic/rock/cantbuy.mid', 'converted_music/miniMusic/classical/017206ch.mid', 'converted_music/miniMusic/classical/017507ch.mid', 'converted_music/miniMusic/classical/017906b_.mid', 'converted_music/miniMusic/rock/dntleten.mid', 'converted_music/miniMusic/rock/breaking_up_is_hard_to_do.mid', 'converted_music/miniMusic/classical/015105b_.mid', 'converted_music/miniMusic/classical/018007b_.mid', 'converted_music/miniMusic/classical/013806b_.mid', 'converted_music/miniMusic/classical/013705b_.mid', 'converted_music/miniMusic/rock/askmewhy.mid', 'converted_music/miniMusic/rock/backussr.mid', 'converted_music/miniMusic/rock/anotherg.mid', 'converted_music/miniMusic/classical/015408b_.mid']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# In[15]:\n",
      "\n",
      "def batch_gen(X, y, N):\n",
      "    while True:\n",
      "        idx = np.random.choice(len(y), N)\n",
      "        xs = []\n",
      "        ys = []\n",
      "        for i in range(N//10):\n",
      "            for x in gen_sample(X[idx[i]]):\n",
      "                xs.append(x)\n",
      "                ys.append(y[idx[i]])\n",
      "        yield np.array(xs), np.array(ys).astype('int32')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        # We need to reshape from a 1D feature vector to a 1 channel 2D image.\n",
      "# Then we apply 3 convolutional filters with 3x3 kernel size.\n",
      "l_in = lasagne.layers.InputLayer((None, 257, 173))\n",
      "\n",
      "l_shape = lasagne.layers.ReshapeLayer(l_in, (-1, 1, 257, 173))\n",
      "\n",
      "l_conv = lasagne.layers.Conv2DLayer(l_shape, num_filters=1, stride=2, filter_size=3, pad='valid')\n",
      "\n",
      "l_conv2 = lasagne.layers.Conv2DLayer(l_conv, num_filters=1, stride=2, filter_size=3, pad='valid')\n",
      "\n",
      "l_conv3 = lasagne.layers.Conv2DLayer(l_conv2, num_filters=1, stride=2, filter_size=3, pad='valid')\n",
      "\n",
      "l_conv4 = lasagne.layers.Conv2DLayer(l_conv3, num_filters=1, stride=2, filter_size=3, pad='valid')\n",
      "\n",
      "l_conv5 = lasagne.layers.Conv2DLayer(l_conv4, num_filters=1, stride=2, filter_size=3, pad='valid')\n",
      "\n",
      "print(lasagne.layers.get_output_shape(l_conv5))\n",
      "l_out = lasagne.layers.DenseLayer(l_conv5,\n",
      "                                  num_units=2,\n",
      "                                  nonlinearity=lasagne.nonlinearities.softmax)\n",
      "layers = ['l_conv', 'l_conv2', 'l_conv3', 'l_conv4', 'l_conv5', 'l_out']\n",
      "net = {}\n",
      "net['l_conv'] = l_conv\n",
      "net['l_conv2'] = l_conv2\n",
      "net['l_conv3'] = l_conv3\n",
      "net['l_conv4'] = l_conv4\n",
      "net['l_conv5'] = l_conv5\n",
      "net['l_out'] = l_out\n",
      "\n",
      "layers = {k: net[k] for k in layers}\n",
      "print(lasagne.layers.get_output_shape(l_conv3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(None, 1, 7, 4)\n",
        "(None, 1, 31, 20)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import librosa as lb\n",
      "def f(x):\n",
      "    return x.imag\n",
      "\n",
      "# f = np.vectorize(f)\n",
      "\n",
      "def gen_sample(filename, n_batch=10):\n",
      "    print(filename)\n",
      "    src, sr = lb.load (filename, sr=11025)\n",
      "    frame_size = sr*4\n",
      "    res = []\n",
      "    idx = np.random.choice(len(src) - frame_size, n_batch)\n",
      "    for pos in idx:\n",
      "        frame = src[pos: pos + frame_size]\n",
      "        SRC = lb.stft (frame, n_fft=512, hop_length=256)\n",
      "        res.append(f(SRC))\n",
      "    return res\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_samples(filename, offset=0):\n",
      "    src, sr = lb.load (filename, sr=11025)\n",
      "    frame_size = sr*4\n",
      "    res = []\n",
      "    for pos in range(len(src)//2, len(src), frame_size):\n",
      "        frame = src[pos: pos + frame_size]\n",
      "        SRC = lb.stft (frame, n_fft=512, hop_length=256)\n",
      "        res.append(f(SRC))\n",
      "        break\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "# In[16]:\n",
      "\n",
      "\n",
      "\n",
      "# Compile and train the network.\n",
      "# Accuracy is much better than the single layer network, despite the small number of filters.\n",
      "X_sym = T.tensor3()\n",
      "y_sym = T.ivector()\n",
      "\n",
      "output = lasagne.layers.get_output(l_out, X_sym)\n",
      "pred = output.argmax(-1)\n",
      "\n",
      "loss = T.mean(lasagne.objectives.categorical_crossentropy(output, y_sym))\n",
      "\n",
      "acc = T.mean(T.eq(pred, y_sym))\n",
      "\n",
      "params = lasagne.layers.get_all_params(l_out)\n",
      "grad = T.grad(loss, params)\n",
      "updates = lasagne.updates.adam(grad, params, learning_rate=0.05)\n",
      "\n",
      "f_train = theano.function([X_sym, y_sym], [loss, acc], updates=updates)\n",
      "f_val = theano.function([X_sym, y_sym], [loss, acc])\n",
      "f_predict = theano.function([X_sym], pred)\n",
      "\n",
      "BATCH_SIZE = 10\n",
      "N_BATCHES = 50\n",
      "N_VAL_BATCHES = 10\n",
      "\n",
      "train_batches = batch_gen(X_train, y_train, BATCH_SIZE)\n",
      "val_batches = batch_gen(X_val, y_val, BATCH_SIZE)\n",
      "\n",
      "for epoch in range(100):\n",
      "    train_loss = 0\n",
      "    train_acc = 0\n",
      "    print(N_BATCHES)\n",
      "    for _ in range(N_BATCHES):\n",
      "        X1, y1 = next(train_batches)\n",
      "        print(X1.shape)\n",
      "        print(y1.shape)\n",
      "        loss, acc = f_train(X1, y1)\n",
      "        train_loss += loss\n",
      "        train_acc += acc\n",
      "    train_loss /= N_BATCHES\n",
      "    train_acc /= N_BATCHES\n",
      "    val_loss = 0\n",
      "    val_acc = 0\n",
      "    for _ in range(N_VAL_BATCHES):\n",
      "        X1, y1 = next(val_batches)\n",
      "        loss, acc = f_val(X1, y1)\n",
      "        val_loss += loss\n",
      "        val_acc += acc\n",
      "    val_loss /= N_VAL_BATCHES\n",
      "    val_acc /= N_VAL_BATCHES\n",
      "    \n",
      "    print('Epoch {}, Train (val) loss {:.03f} ({:.03f}) ratio {:.03f}'.format(\n",
      "            epoch, train_loss, val_loss, val_loss/train_loss))\n",
      "    print('Train (val) accuracy {:.03f} ({:.03f})'.format(train_acc, val_acc))\n",
      "\n",
      "    all_weights = lasagne.layers.get_all_param_values(layers.values())\n",
      "    pickle.dump(all_weights, open('weights{:.03f}.pkl'.format(val_acc), 'wb+'), pickle.HIGHEST_PROTOCOL)\n",
      "# In[ ]:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = pickle.load(open('weights.pkl'))['param values']\n",
      "lasagne.layers.set_all_param_values(layers, values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gram_matrix(x):\n",
      "    x = x.flatten(ndim=3)\n",
      "    g = T.tensordot(x, x, axes=([2], [2]))\n",
      "    return g\n",
      "\n",
      "\n",
      "def content_loss(P, X, layer):\n",
      "    p = P[layer]\n",
      "    x = X[layer]\n",
      "    \n",
      "    loss = 1./2 * ((x - p)**2).sum()\n",
      "    return loss\n",
      "\n",
      "\n",
      "def style_loss(A, X, layer):\n",
      "    a = A[layer]\n",
      "    x = X[layer]\n",
      "    \n",
      "    A = gram_matrix(a)\n",
      "    G = gram_matrix(x)\n",
      "    \n",
      "    N = a.shape[1]\n",
      "    M = a.shape[2] * a.shape[3]\n",
      "    \n",
      "    loss = 1./(4 * N**2 * M**2) * ((G - A)**2).sum()\n",
      "    return loss\n",
      "\n",
      "def total_variation_loss(x):\n",
      "    return (((x[:,:-1,:-1] - x[:,1:,:-1])**2 + (x[:,:-1,:-1] - x[:,:-1,1:])**2)**1.25).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "style_samples = get_samples('converted_music/miniMusic/acrossu.mid')\n",
      "target_samples = get_samples('converted_music/miniMusic/013705b_.mid')\n",
      "style_music = style_samples[0]\n",
      "target_music = target_samples[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_im_theano = T.matrix()\n",
      "outputs = lasagne.layers.get_output(layers.values(), input_im_theano)\n",
      "\n",
      "target_features = {k: theano.shared(output.eval({input_im_theano: target_music}))\n",
      "                  for k, output in zip(layers.keys(), outputs)}\n",
      "style_features = {k: theano.shared(output.eval({input_im_theano: style_music}))\n",
      "                for k, output in zip(layers.keys(), outputs)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "generated_music = theano.shared(floatX(np.random.uniform(-128, 128, (1, 257, 173))))\n",
      "\n",
      "gen_features = lasagne.layers.get_output(layers.values(), generated_music)\n",
      "gen_features = {k: v for k, v in zip(layers.keys(), gen_features)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define loss function\n",
      "losses = []\n",
      "\n",
      "# content loss\n",
      "losses.append(0.001 * content_loss(target_features, gen_features, 'conv4_2'))\n",
      "\n",
      "# style loss\n",
      "losses.append(0.2e6 * style_loss(style_features, gen_features, 'conv1_1'))\n",
      "losses.append(0.2e6 * style_loss(style_features, gen_features, 'conv2_1'))\n",
      "losses.append(0.2e6 * style_loss(style_features, gen_features, 'conv3_1'))\n",
      "losses.append(0.2e6 * style_loss(style_features, gen_features, 'conv4_1'))\n",
      "losses.append(0.2e6 * style_loss(style_features, gen_features, 'conv5_1'))\n",
      "\n",
      "# total variation penalty\n",
      "losses.append(0.1e-7 * total_variation_loss(generated_music))\n",
      "\n",
      "total_loss = sum(losses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}